/**
 * LangGraph å·¥ä½œæµå®ç°
 */

import { StateGraph, END, START } from "@langchain/langgraph";
import { ChatOpenAI } from "@langchain/openai";
import { HumanMessage, SystemMessage } from "@langchain/core/messages";

export interface DiagnosticState {
  error: any;
  analysis: string;
  suggestion: string;
  fixedCode: string;
  filePath: string;
  autoFix: boolean;
  retryCount: number;
  messages: any[];
}

export class DiagnosticGraph {
  private llm: ChatOpenAI;
  private graph: any;
  private maxRetries: number;

  constructor(
    apiKey: string,
    apiUrl: string,
    model: string = "gpt-4",
    maxRetries: number = 3,
    temperature: number = 0.1,
    maxTokens: number = 4000,
  ) {
    this.maxRetries = maxRetries;

    console.log("ğŸ”§ [LangGraph] åˆå§‹åŒ– LLM...");
    console.log("ğŸ“ [é…ç½®] æ¨¡å‹:", model);
    console.log("ğŸ“ [é…ç½®] API URL:", apiUrl);
    console.log("ğŸ“ [é…ç½®] API Key:", apiKey ? "å·²é…ç½®" : "æœªé…ç½®");

    // åˆ›å»ºé…ç½®å¯¹è±¡ï¼Œä¸åŒ…å« top_pï¼ˆé¿å…ä¸ Claude ç­‰æ¨¡å‹å†²çªï¼‰
    const llmConfig: any = {
      openAIApiKey: apiKey,
      configuration: {
        baseURL: apiUrl,
      },
      modelName: model,
      temperature,
      maxTokens,
    };

    this.llm = new ChatOpenAI(llmConfig);

    // è¦†ç›– invocationParams æ–¹æ³•ï¼Œç§»é™¤ top_p å‚æ•°
    // è¿™æ˜¯ä¸ºäº†å…¼å®¹ Claude ç­‰ä¸æ”¯æŒåŒæ—¶ä½¿ç”¨ temperature å’Œ top_p çš„æ¨¡å‹
    const originalInvocationParams = this.llm.invocationParams.bind(this.llm);
    this.llm.invocationParams = (options: any) => {
      const params = originalInvocationParams(options);
      delete params.top_p;
      return params;
    };

    this.graph = this.buildGraph();
  }

  private buildGraph() {
    const workflow = new StateGraph<DiagnosticState>({
      channels: {
        error: null,
        analysis: null,
        suggestion: null,
        fixedCode: null,
        filePath: null,
        autoFix: null,
        retryCount: null,
        messages: null,
      },
    });

    workflow.addNode("analyze", this.analyzeNode.bind(this));
    workflow.addNode("suggest", this.suggestNode.bind(this));
    // è‡ªåŠ¨ä¿®å¤èŠ‚ç‚¹å·²æ³¨é‡Šï¼ˆåŠŸèƒ½ä¸å¤Ÿç¨³å®šï¼‰
    // workflow.addNode("fix", this.fixNode.bind(this));
    // workflow.addNode("validate", this.validateNode.bind(this));

    workflow.addEdge(START, "analyze");
    workflow.addEdge("analyze", "suggest");
    // ç›´æ¥ç»“æŸï¼Œä¸å†è¿›è¡Œè‡ªåŠ¨ä¿®å¤
    workflow.addEdge("suggest", END);

    // è‡ªåŠ¨ä¿®å¤æµç¨‹å·²æ³¨é‡Š
    // workflow.addConditionalEdges("suggest", this.shouldFix.bind(this), {
    //   fix: "fix",
    //   end: END,
    // });
    // workflow.addEdge("fix", "validate");
    // workflow.addConditionalEdges("validate", this.shouldRetry.bind(this), {
    //   retry: "analyze",
    //   end: END,
    // });

    return workflow.compile();
  }

  private async analyzeNode(
    state: DiagnosticState,
  ): Promise<Partial<DiagnosticState>> {
    console.log("ğŸ” [LangGraph] æ­£åœ¨åˆ†æé”™è¯¯...");

    const systemPrompt = new SystemMessage(
      "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å‰ç«¯ä»£ç è¯Šæ–­ä¸“å®¶ï¼Œç²¾é€š Vue3ã€TypeScriptã€Vite å’Œ uni-appã€‚è¯·ç®€æ´æ˜äº†åœ°åˆ†æé—®é¢˜ã€‚",
    );

    const userPrompt = new HumanMessage(`
è¯·åˆ†æä»¥ä¸‹æ„å»ºé”™è¯¯ï¼š

é”™è¯¯ç±»å‹: ${state.error.type}
é”™è¯¯ä¿¡æ¯: ${state.error.message}
æ–‡ä»¶è·¯å¾„: ${state.error.file || "æœªçŸ¥"}

è¯·ç®€æ´åœ°è¯´æ˜ï¼ˆ3-5å¥è¯ï¼‰ï¼š
1. é”™è¯¯çš„æ ¹æœ¬åŸå› 
2. å½±å“èŒƒå›´
3. ä¸¥é‡ç¨‹åº¦
`);

    const response = await this.llm.invoke([systemPrompt, userPrompt]);
    const analysis = response.content.toString();

    return {
      analysis,
      messages: [...(state.messages || []), systemPrompt, userPrompt, response],
    };
  }

  private async suggestNode(
    state: DiagnosticState,
  ): Promise<Partial<DiagnosticState>> {
    console.log("ğŸ’¡ [LangGraph] æ­£åœ¨ç”Ÿæˆä¿®å¤å»ºè®®...");

    // æå–é”™è¯¯ç›¸å…³çš„ä»£ç ç‰‡æ®µ
    let codeContext = "";
    if (state.error.code && state.error.message) {
      // å°è¯•ä»é”™è¯¯ä¿¡æ¯ä¸­æå–è¡Œå·
      const lineMatch = state.error.message.match(/\((\d+):(\d+)\)/);
      if (lineMatch) {
        const errorLine = parseInt(lineMatch[1]);
        const lines = state.error.code.split("\n");

        // æå–é”™è¯¯è¡Œå‰åå„5è¡Œä½œä¸ºä¸Šä¸‹æ–‡
        const startLine = Math.max(0, errorLine - 6);
        const endLine = Math.min(lines.length, errorLine + 4);
        const contextLines = lines.slice(startLine, endLine);

        codeContext = `
ç›¸å…³ä»£ç ç‰‡æ®µï¼ˆç¬¬ ${startLine + 1}-${endLine} è¡Œï¼‰ï¼š
\`\`\`
${contextLines
  .map((line, idx) => {
    const lineNum = startLine + idx + 1;
    const marker = lineNum === errorLine ? " â† é”™è¯¯ä½ç½®" : "";
    return `${lineNum}: ${line}${marker}`;
  })
  .join("\n")}
\`\`\`
`;
      } else if (state.error.code.length < 2000) {
        // å¦‚æœä»£ç ä¸é•¿ï¼Œæ˜¾ç¤ºå®Œæ•´ä»£ç 
        codeContext = `
å®Œæ•´ä»£ç ï¼š
\`\`\`
${state.error.code}
\`\`\`
`;
      }
    }

    const userPrompt = new HumanMessage(`
åŸºäºä»¥ä¸‹é”™è¯¯åˆ†æï¼Œè¯·æä¾›å…·ä½“çš„ä¿®å¤å»ºè®®ï¼š

é”™è¯¯åˆ†æï¼š
${state.analysis}

é”™è¯¯è¯¦æƒ…ï¼š
- ç±»å‹: ${state.error.type}
- ä¿¡æ¯: ${state.error.message}
- æ–‡ä»¶: ${state.error.file || "æœªçŸ¥"}

${codeContext}

è¯·æä¾›ç²¾ç¡®çš„ä¿®å¤å»ºè®®ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š

1. ä¿®å¤æ­¥éª¤:
   1. [å…·ä½“æ­¥éª¤1]
   2. [å…·ä½“æ­¥éª¤2]
   3. [å…·ä½“æ­¥éª¤3]

2. éœ€è¦ä¿®æ”¹çš„ä»£ç ä½ç½®: [æ–‡ä»¶å] çš„ç¬¬ [X] è¡Œ

3. ä¿®æ”¹åçš„ä»£ç ç¤ºä¾‹:
   \`\`\`[è¯­è¨€]
   [åªæ˜¾ç¤ºéœ€è¦ä¿®æ”¹çš„é‚£å‡ è¡Œä»£ç ï¼Œä¿æŒåŸæœ‰ç¼©è¿›]
   \`\`\`

4. é¢„é˜²å»ºè®®: [ä¸€å¥è¯è¯´æ˜å¦‚ä½•é¿å…ç±»ä¼¼é”™è¯¯]

æ³¨æ„ï¼š
- ä»£ç ç¤ºä¾‹å¿…é¡»åŸºäºå®é™…çš„æºä»£ç ï¼Œä¿æŒæ­£ç¡®çš„è¯­æ³•å’Œç¼©è¿›
- åªæ˜¾ç¤ºéœ€è¦ä¿®æ”¹çš„å…³é”®ä»£ç è¡Œï¼Œä¸è¦æ˜¾ç¤ºæ•´ä¸ªæ–‡ä»¶
- ç¡®ä¿ä¿®æ”¹åçš„ä»£ç å¯ä»¥ç›´æ¥ä½¿ç”¨
`);

    const response = await this.llm.invoke([...state.messages, userPrompt]);
    const suggestion = response.content.toString();

    return {
      suggestion,
      messages: [...state.messages, userPrompt, response],
    };
  }

  // è‡ªåŠ¨ä¿®å¤èŠ‚ç‚¹å·²æ³¨é‡Šï¼ˆåŠŸèƒ½ä¸å¤Ÿç¨³å®šï¼‰
  // private async fixNode(
  //   state: DiagnosticState
  // ): Promise<Partial<DiagnosticState>> {
  //   console.log("ğŸ”§ [LangGraph] æ­£åœ¨ç”Ÿæˆä¿®å¤ä»£ç ...");

  //   if (!state.error.code || !state.error.file) {
  //     return { fixedCode: "", filePath: "" };
  //   }

  //   try {
  //     const systemPrompt = new SystemMessage(
  //       `ä½ æ˜¯ä»£ç ä¿®å¤åŠ©æ‰‹ã€‚è¿”å›ä¿®å¤åçš„å®Œæ•´æ–‡ä»¶å†…å®¹ï¼Œä¸è¦è§£é‡Šã€‚`
  //     );

  //     const userPrompt = new HumanMessage(`
  // æ–‡ä»¶ï¼ˆ${state.error.code.split("\n").length} è¡Œï¼‰ï¼š
  // ${state.error.code}

  // é”™è¯¯ï¼š${state.error.message}

  // è¾“å‡ºä¿®å¤åçš„å®Œæ•´æ–‡ä»¶ï¼š
  // `);

  //     console.log("ğŸ“¤ [è°ƒè¯•] å‘é€ä¿®å¤è¯·æ±‚...");
  //     console.log(
  //       "ğŸ“¤ [è°ƒè¯•] åŸå§‹æ–‡ä»¶è¡Œæ•°:",
  //       state.error.code.split("\n").length
  //     );

  //     const response = await this.llm.invoke([systemPrompt, userPrompt]);
  //     let fixedCode = response.content.toString().trim();

  //     console.log("ğŸ“¥ [è°ƒè¯•] AI è¿”å›å†…å®¹é•¿åº¦:", fixedCode.length);
  //     console.log("ğŸ“¥ [è°ƒè¯•] åŸå§‹ä»£ç é•¿åº¦:", state.error.code.length);
  //     console.log("ğŸ“¥ [è°ƒè¯•] è¿”å›å†…å®¹è¡Œæ•°:", fixedCode.split("\n").length);

  //     if (fixedCode.length === 0) {
  //       console.error("âŒ [è°ƒè¯•] AI è¿”å›ç©ºå†…å®¹ï¼Œå¯èƒ½æ˜¯ API è°ƒç”¨å¤±è´¥");
  //       return { fixedCode: "", filePath: "" };
  //     }

  //     fixedCode = fixedCode
  //       .replace(/^```[\w]*\n?/gm, "")
  //       .replace(/\n?```$/gm, "")
  //       .trim();

  //     console.log("ğŸ“¥ [è°ƒè¯•] æ¸…ç†åå†…å®¹é•¿åº¦:", fixedCode.length);

  //     const finalLengthRatio = fixedCode.length / state.error.code.length;
  //     console.log(
  //       `âœ… [è°ƒè¯•] æœ€ç»ˆä»£ç é•¿åº¦æ¯”ä¾‹: ${(finalLengthRatio * 100).toFixed(0)}%`
  //     );

  //     return {
  //       fixedCode,
  //       filePath: state.error.file,
  //       messages: [...state.messages, userPrompt, response],
  //     };
  //   } catch (error: any) {
  //     console.error("âŒ [è°ƒè¯•] fixNode æ‰§è¡Œå¤±è´¥:", error.message);
  //     return { fixedCode: "", filePath: "" };
  //   }
  // }

  // private async validateNode(
  //   state: DiagnosticState
  // ): Promise<Partial<DiagnosticState>> {
  //   console.log("âœ… [LangGraph] æ­£åœ¨éªŒè¯ä¿®å¤...");
  //   return state;
  // }

  // private shouldFix(state: DiagnosticState): string {
  //   if (state.autoFix && state.error.file && state.error.code) {
  //     return "fix";
  //   }
  //   return "end";
  // }

  // private shouldRetry(state: DiagnosticState): string {
  //   if (state.retryCount < this.maxRetries && !state.fixedCode) {
  //     return "retry";
  //   }
  //   return "end";
  // }

  async run(error: any, autoFix: boolean = false): Promise<DiagnosticState> {
    const initialState: DiagnosticState = {
      error,
      analysis: "",
      suggestion: "",
      fixedCode: "",
      filePath: "",
      autoFix,
      retryCount: 0,
      messages: [],
    };

    try {
      console.log("ğŸš€ [LangGraph] å¯åŠ¨è¯Šæ–­å·¥ä½œæµ...\n");
      const result = await this.graph.invoke(initialState);
      console.log("âœ¨ [LangGraph] è¯Šæ–­å·¥ä½œæµå®Œæˆ\n");
      return result;
    } catch (error: any) {
      console.error("âŒ [LangGraph] å·¥ä½œæµæ‰§è¡Œå¤±è´¥:", error.message);
      throw error;
    }
  }
}
