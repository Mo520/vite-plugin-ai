/**
 * LangGraph å·¥ä½œæµå®ç°
 */

import { StateGraph, END, START } from "@langchain/langgraph";
import { ChatOpenAI } from "@langchain/openai";
import { HumanMessage, SystemMessage } from "@langchain/core/messages";

export interface DiagnosticState {
  error: any;
  analysis: string;
  suggestion: string;
  fixedCode: string;
  filePath: string;
  autoFix: boolean;
  retryCount: number;
  messages: any[];
}

export class DiagnosticGraph {
  private llm: ChatOpenAI;
  private graph: any;
  private maxRetries: number;

  constructor(
    apiKey: string,
    apiUrl: string,
    model: string = "gpt-4",
    maxRetries: number = 3
  ) {
    this.maxRetries = maxRetries;

    console.log("ğŸ”§ [LangGraph] åˆå§‹åŒ– LLM...");
    console.log("ğŸ“ [é…ç½®] æ¨¡å‹:", model);
    console.log("ğŸ“ [é…ç½®] API URL:", apiUrl);
    console.log("ğŸ“ [é…ç½®] API Key:", apiKey ? "å·²é…ç½®" : "æœªé…ç½®");

    this.llm = new ChatOpenAI({
      openAIApiKey: apiKey,
      configuration: {
        baseURL: apiUrl,
      },
      modelName: model,
      temperature: 0.1,
      maxTokens: 4000,
    });

    this.graph = this.buildGraph();
  }

  private buildGraph() {
    const workflow = new StateGraph<DiagnosticState>({
      channels: {
        error: null,
        analysis: null,
        suggestion: null,
        fixedCode: null,
        filePath: null,
        autoFix: null,
        retryCount: null,
        messages: null,
      },
    });

    workflow.addNode("analyze", this.analyzeNode.bind(this));
    workflow.addNode("suggest", this.suggestNode.bind(this));
    // è‡ªåŠ¨ä¿®å¤èŠ‚ç‚¹å·²æ³¨é‡Šï¼ˆåŠŸèƒ½ä¸å¤Ÿç¨³å®šï¼‰
    // workflow.addNode("fix", this.fixNode.bind(this));
    // workflow.addNode("validate", this.validateNode.bind(this));

    workflow.addEdge(START, "analyze");
    workflow.addEdge("analyze", "suggest");
    // ç›´æ¥ç»“æŸï¼Œä¸å†è¿›è¡Œè‡ªåŠ¨ä¿®å¤
    workflow.addEdge("suggest", END);

    // è‡ªåŠ¨ä¿®å¤æµç¨‹å·²æ³¨é‡Š
    // workflow.addConditionalEdges("suggest", this.shouldFix.bind(this), {
    //   fix: "fix",
    //   end: END,
    // });
    // workflow.addEdge("fix", "validate");
    // workflow.addConditionalEdges("validate", this.shouldRetry.bind(this), {
    //   retry: "analyze",
    //   end: END,
    // });

    return workflow.compile();
  }

  private async analyzeNode(
    state: DiagnosticState
  ): Promise<Partial<DiagnosticState>> {
    console.log("ğŸ” [LangGraph] æ­£åœ¨åˆ†æé”™è¯¯...");

    const systemPrompt = new SystemMessage(
      "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å‰ç«¯ä»£ç è¯Šæ–­ä¸“å®¶ï¼Œç²¾é€š Vue3ã€TypeScriptã€Vite å’Œ uni-appã€‚è¯·ç®€æ´æ˜äº†åœ°åˆ†æé—®é¢˜ã€‚"
    );

    const userPrompt = new HumanMessage(`
è¯·åˆ†æä»¥ä¸‹æ„å»ºé”™è¯¯ï¼š

é”™è¯¯ç±»å‹: ${state.error.type}
é”™è¯¯ä¿¡æ¯: ${state.error.message}
æ–‡ä»¶è·¯å¾„: ${state.error.file || "æœªçŸ¥"}

è¯·ç®€æ´åœ°è¯´æ˜ï¼ˆ3-5å¥è¯ï¼‰ï¼š
1. é”™è¯¯çš„æ ¹æœ¬åŸå› 
2. å½±å“èŒƒå›´
3. ä¸¥é‡ç¨‹åº¦
`);

    const response = await this.llm.invoke([systemPrompt, userPrompt]);
    const analysis = response.content.toString();

    return {
      analysis,
      messages: [...(state.messages || []), systemPrompt, userPrompt, response],
    };
  }

  private async suggestNode(
    state: DiagnosticState
  ): Promise<Partial<DiagnosticState>> {
    console.log("ğŸ’¡ [LangGraph] æ­£åœ¨ç”Ÿæˆä¿®å¤å»ºè®®...");

    const userPrompt = new HumanMessage(`
åŸºäºä»¥ä¸‹é”™è¯¯åˆ†æï¼Œè¯·æä¾›å…·ä½“çš„ä¿®å¤å»ºè®®ï¼š

é”™è¯¯åˆ†æï¼š
${state.analysis}

é”™è¯¯è¯¦æƒ…ï¼š
- ç±»å‹: ${state.error.type}
- ä¿¡æ¯: ${state.error.message}
- æ–‡ä»¶: ${state.error.file || "æœªçŸ¥"}

è¯·ç®€æ´åœ°æä¾›ï¼š
1. å…·ä½“çš„ä¿®å¤æ­¥éª¤ï¼ˆ3-5æ­¥å³å¯ï¼‰
2. éœ€è¦ä¿®æ”¹çš„ä»£ç ä½ç½®ï¼ˆè¡Œå·ï¼‰
3. ä¿®æ”¹åçš„ä»£ç ç¤ºä¾‹ï¼ˆåªæ˜¾ç¤ºå…³é”®éƒ¨åˆ†ï¼‰
4. ä¸€å¥è¯é¢„é˜²å»ºè®®

æ³¨æ„ï¼šè¯·ç›´æ¥ç»™å‡ºå»ºè®®ï¼Œä¸è¦é‡å¤é”™è¯¯åˆ†æçš„å†…å®¹ã€‚
`);

    const response = await this.llm.invoke([...state.messages, userPrompt]);
    const suggestion = response.content.toString();

    return {
      suggestion,
      messages: [...state.messages, userPrompt, response],
    };
  }

  // è‡ªåŠ¨ä¿®å¤èŠ‚ç‚¹å·²æ³¨é‡Šï¼ˆåŠŸèƒ½ä¸å¤Ÿç¨³å®šï¼‰
  // private async fixNode(
  //   state: DiagnosticState
  // ): Promise<Partial<DiagnosticState>> {
  //   console.log("ğŸ”§ [LangGraph] æ­£åœ¨ç”Ÿæˆä¿®å¤ä»£ç ...");

  //   if (!state.error.code || !state.error.file) {
  //     return { fixedCode: "", filePath: "" };
  //   }

  //   try {
  //     const systemPrompt = new SystemMessage(
  //       `ä½ æ˜¯ä»£ç ä¿®å¤åŠ©æ‰‹ã€‚è¿”å›ä¿®å¤åçš„å®Œæ•´æ–‡ä»¶å†…å®¹ï¼Œä¸è¦è§£é‡Šã€‚`
  //     );

  //     const userPrompt = new HumanMessage(`
  // æ–‡ä»¶ï¼ˆ${state.error.code.split("\n").length} è¡Œï¼‰ï¼š
  // ${state.error.code}

  // é”™è¯¯ï¼š${state.error.message}

  // è¾“å‡ºä¿®å¤åçš„å®Œæ•´æ–‡ä»¶ï¼š
  // `);

  //     console.log("ğŸ“¤ [è°ƒè¯•] å‘é€ä¿®å¤è¯·æ±‚...");
  //     console.log(
  //       "ğŸ“¤ [è°ƒè¯•] åŸå§‹æ–‡ä»¶è¡Œæ•°:",
  //       state.error.code.split("\n").length
  //     );

  //     const response = await this.llm.invoke([systemPrompt, userPrompt]);
  //     let fixedCode = response.content.toString().trim();

  //     console.log("ğŸ“¥ [è°ƒè¯•] AI è¿”å›å†…å®¹é•¿åº¦:", fixedCode.length);
  //     console.log("ğŸ“¥ [è°ƒè¯•] åŸå§‹ä»£ç é•¿åº¦:", state.error.code.length);
  //     console.log("ğŸ“¥ [è°ƒè¯•] è¿”å›å†…å®¹è¡Œæ•°:", fixedCode.split("\n").length);

  //     if (fixedCode.length === 0) {
  //       console.error("âŒ [è°ƒè¯•] AI è¿”å›ç©ºå†…å®¹ï¼Œå¯èƒ½æ˜¯ API è°ƒç”¨å¤±è´¥");
  //       return { fixedCode: "", filePath: "" };
  //     }

  //     fixedCode = fixedCode
  //       .replace(/^```[\w]*\n?/gm, "")
  //       .replace(/\n?```$/gm, "")
  //       .trim();

  //     console.log("ğŸ“¥ [è°ƒè¯•] æ¸…ç†åå†…å®¹é•¿åº¦:", fixedCode.length);

  //     const finalLengthRatio = fixedCode.length / state.error.code.length;
  //     console.log(
  //       `âœ… [è°ƒè¯•] æœ€ç»ˆä»£ç é•¿åº¦æ¯”ä¾‹: ${(finalLengthRatio * 100).toFixed(0)}%`
  //     );

  //     return {
  //       fixedCode,
  //       filePath: state.error.file,
  //       messages: [...state.messages, userPrompt, response],
  //     };
  //   } catch (error: any) {
  //     console.error("âŒ [è°ƒè¯•] fixNode æ‰§è¡Œå¤±è´¥:", error.message);
  //     return { fixedCode: "", filePath: "" };
  //   }
  // }

  // private async validateNode(
  //   state: DiagnosticState
  // ): Promise<Partial<DiagnosticState>> {
  //   console.log("âœ… [LangGraph] æ­£åœ¨éªŒè¯ä¿®å¤...");
  //   return state;
  // }

  // private shouldFix(state: DiagnosticState): string {
  //   if (state.autoFix && state.error.file && state.error.code) {
  //     return "fix";
  //   }
  //   return "end";
  // }

  // private shouldRetry(state: DiagnosticState): string {
  //   if (state.retryCount < this.maxRetries && !state.fixedCode) {
  //     return "retry";
  //   }
  //   return "end";
  // }

  async run(error: any, autoFix: boolean = false): Promise<DiagnosticState> {
    const initialState: DiagnosticState = {
      error,
      analysis: "",
      suggestion: "",
      fixedCode: "",
      filePath: "",
      autoFix,
      retryCount: 0,
      messages: [],
    };

    try {
      console.log("ğŸš€ [LangGraph] å¯åŠ¨è¯Šæ–­å·¥ä½œæµ...\n");
      const result = await this.graph.invoke(initialState);
      console.log("âœ¨ [LangGraph] è¯Šæ–­å·¥ä½œæµå®Œæˆ\n");
      return result;
    } catch (error: any) {
      console.error("âŒ [LangGraph] å·¥ä½œæµæ‰§è¡Œå¤±è´¥:", error.message);
      throw error;
    }
  }
}
